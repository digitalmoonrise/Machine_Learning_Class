{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You go through the models one by one and search over all models with one feature and select the one with the lowest RSS and then you go through all the models with 2 features and select the one with the lowest rss and so on and so forth. ####Models do not necessarily need to contain the previous best feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have the models, you can test them on a validation set or use cross validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Complexity of 'all subsets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity of a model is 2^D. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if you had 8 features, you would have 2^8 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, an all subsets search is too computationally intensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Greedy Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Forward stepwise algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick set of features and then simply recurse over the features adding the feature that lowers the RSS by the greatest amount. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first best feature is going to be the same as the all subset solution becauses one feature is going to be the best in either case. So your model will be D = w1\n",
    "\n",
    "2. The second step is going to look different though because we're going to keep the first best feature, and then you'd add the feature that most lowers RSS. Model D = w1 + w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the greedy method, the training error will never increase. Eventually, and obviously, training error will match the all subsets model because all features will be included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####When do you stop?\n",
    "#####Always validation or cross validation -- do not use your test or train data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Complexity for greedy heuristic: O(D^2) << 2^D\n",
    "\n",
    "n(n+1)/2 is the formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Lasso aka Lsub1 regularized regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: Ridge regression total cost = Measure of fit(RSS) + λ measure of coefficients. For any finite value of lambda, the coefficient will not go to 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why can't you just threshold ridge coefficients -- i.e. when w is close to 0, just get rid of it. No, Because this is linear regression and correlated features are going to effect the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l1 cost = RSS(w) + λ||w||sub1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case λ is balance of fit and sparsity. \n",
    "\n",
    "if λ = 0, w-hat lasso = w-hat least squares. \n",
    "if λ = infinity w-hat lasso = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no closed form solution for lasso objective. (Closed form means that the constant is set to 0) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Coordinate Descent (Very important Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axis aligned steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####How to pick coordinates?\n",
    "#######Random or ''stochasitic''? Round robin (Just cycling)?\n",
    "\n",
    "#####There is no step size to choose stepsize in coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Normalizing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizer = Zj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is an _ [underbar] it means that the features are normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Optimizing least squares objective one coordinate at a time. \n",
    " -2Pj + 2Wj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####When we set partial to 0 (use a closed form solution?) the formula is ##W-hat-j = Pj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Coordinate descent for lasso\n",
    "\n",
    "Wj = Pj + λ/2 if Pj < -λ/2\n",
    "Wj = 0 if Pj in [-λ/2,λ/2]\n",
    "Wj = Pj -λ/2 if Pj > λ/2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.false\n",
    "2.1048576\n",
    "3.400, 20, 210\n",
    "4. 1 and 2, 2, 2 and 4 STILL WRONG\n",
    "5. 4, 3, 2\n",
    "6.1\n",
    "7.1, 2 , 3 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Most popular lasso solvers now is Parallel CD (eg. shotgun [bradley]) or ADMM [Boyd] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1:20,]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 1:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
